{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atish3/rob_535_final_project/blob/main/ROB535_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "714Z5mVhSP1r",
        "outputId": "9c6b6a43-10ad-4a1c-f4ad-b8bfe47b4c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co1lj6C4JZ1D",
        "outputId": "f6b00615-7454-47fd-a04e-189aa52e240a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "'''\n",
        "In this cell, we define our neural network\n",
        "and a couple of normalization scripts\n",
        "'''\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(NeuralNetwork, self).__init__()\n",
        "      self.vgg_16 = nn.Sequential(\n",
        "        nn.Conv2d(3,64,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(64,128,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128,128,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(128,256,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256,256,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256,256,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(256,512,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(512,512,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512,512,3,padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(25088,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(4096,3)\n",
        "    ).to(device)\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.image_mean = torch.mean(X, axis=(0,2,3))\n",
        "        self.image_std = torch.std(X, axis=(0,2,3))\n",
        "\n",
        "    def transform(self, X):\n",
        "        img_transforms = nn.Sequential(\n",
        "          transforms.Normalize(self.image_mean, self.image_std) \n",
        "        )\n",
        "        X = img_transforms(X)\n",
        "        return X\n",
        "\n",
        "    def forward(self, x):\n",
        "      self.fit(x)\n",
        "      x = self.transform(x)\n",
        "      logits = self.vgg_16(x)\n",
        "      return logits\n",
        "\n",
        "    def init_weights(self, m):\n",
        "      if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "      elif isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.fill(0.01)\n",
        "        m.bias.data.fill(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8WJntkontcX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from skimage.transform import resize\n",
        "\n",
        "'''\n",
        "In this cell, we define a custom dataset to read in\n",
        "the resized dataset images\n",
        "'''\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, train=True):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_dir = self.img_labels.iloc[idx,0]\n",
        "        img_directory = img_dir.split(\"/\")\n",
        "        label = None\n",
        "        img_name = img_directory[1] + \"_image.jpg\"\n",
        "        img_path = os.path.join(self.img_dir, img_directory[0], img_name)\n",
        "        image = read_image(img_path).float()\n",
        "        if(self.train):\n",
        "            label = self.img_labels.iloc[idx, 1]\n",
        "            \n",
        "        if(self.train):\n",
        "            return image, label\n",
        "        else:\n",
        "            return image, img_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z_ua2yeo-gV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "\n",
        "'''\n",
        "We read in the training and validation sets\n",
        "in this cell\n",
        "'''\n",
        "\n",
        "training_data = CustomImageDataset(\"/content/drive/Shareddrives/ROB 535 Perception Project/trainval/labels.csv\", \"/content/drive/Shareddrives/ROB 535 Perception Project/new_trainval\")\n",
        "\n",
        "train_size = int(0.6*len(training_data))\n",
        "val_size = len(training_data) - train_size\n",
        "\n",
        "train_data, val_data = random_split(training_data, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=1, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYCJrjLtUEkH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "#This function returns the prediction\n",
        "#for each image by extracting the index\n",
        "#with the highest value in each row\n",
        "def predictions(logits):\n",
        "  return torch.argmax(logits, dim=1)\n",
        "\n",
        "\n",
        "#Training loop for the neural network\n",
        "def train_epoch(data_loader, model, criterion, optimizer):\n",
        "    batch_num = 0\n",
        "    for i, (X, y) in enumerate(data_loader):\n",
        "        # clear parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(X)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(batch_num)\n",
        "        batch_num += 1\n",
        "\n",
        "\n",
        "#Evaluation loop for the validation set\n",
        "def evaluate_epoch(tr_loader, val_loader, model, criterion, epoch,\n",
        "    stats):\n",
        "    y_true, y_pred = [], []\n",
        "    correct, total = 0, 0\n",
        "    running_loss = []\n",
        "\n",
        "    for X, y, in tr_loader:\n",
        "        with torch.no_grad():\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "          \n",
        "            output = model(X)\n",
        "            predicted = predictions(output.data)\n",
        "            y_true.append(y)\n",
        "            y_pred.append(predicted)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            running_loss.append(criterion(output, y).item())\n",
        "    train_loss = np.mean(running_loss)\n",
        "    train_acc = correct / total\n",
        "    y_true, y_pred = [], []\n",
        "    correct, total = 0, 0\n",
        "    running_loss = []\n",
        "\n",
        "    for X, y, in val_loader:\n",
        "        with torch.no_grad():\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(X)\n",
        "            predicted = predictions(output.data)\n",
        "            y_true.append(y)\n",
        "            y_pred.append(predicted)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            running_loss.append(criterion(output, y).item())\n",
        "    val_loss = np.mean(running_loss)\n",
        "    val_acc = correct / total\n",
        "    stats.append([val_acc, val_loss, train_acc, train_loss])\n",
        "\n",
        "\n",
        "\n",
        "#Model initialization\n",
        "epoch_num = 0\n",
        "best_val = 0\n",
        "best_ep = 0\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "weights = torch.tensor([1/564, 1/4803, 1/2206])\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=weights).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "#Creating checkpoint filepath\n",
        "if(not os.path.isdir(\"/content/drive/Shareddrives/ROB 535 Perception Project/final_checkpoints\")):\n",
        "  os.mkdir(\"/content/drive/Shareddrives/ROB 535 Perception Project/final_checkpoints\")\n",
        "\n",
        "#Stores training and validation info across epochs\n",
        "stats = []\n",
        "\n",
        "\n",
        "#Training loop\n",
        "for epoch in range(25):\n",
        "        # Train model\n",
        "        print(epoch)\n",
        "        model.train()\n",
        "        train_epoch(train_dataloader, model, criterion, optimizer)\n",
        "\n",
        "        # Evaluate model\n",
        "        model.eval()\n",
        "        evaluate_epoch(train_dataloader, val_dataloader, model, criterion, epoch+1,\n",
        "            stats)\n",
        "        print(stats[-1])\n",
        "\n",
        "        #Save checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': stats[-1][0],\n",
        "            }, \"/content/drive/Shareddrives/ROB 535 Perception Project/test_checkpoints/checkpoint_new_{0}.pt\".format(epoch))\n",
        "        \n",
        "        #Update if we find a better trained model at any epoch\n",
        "        if(stats[-1][0] > best_val):\n",
        "            best_val = stats[-1][0]\n",
        "            best_ep = epoch\n",
        "\n",
        "print(best_ep, best_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This cell loads in the test data and the model used for submission\n",
        "It runs the model against the current training and validation set, capturing\n",
        "the training and validation accuracy and loss at that epoch, and then\n",
        "generates a file of labels for the test data.\n",
        "\n",
        "To regenerate a test data file, uncomment the commented lines below.\n",
        "The final submission file is saved at \n",
        "/content/drive/Shareddrives/ROB 535 Perception Project/test/output.csv\n",
        "'''\n",
        "\n",
        "\n",
        "def eval_test(test_loader, model):\n",
        "  img_num = 1\n",
        "  out_file = open(\"/content/drive/Shareddrives/ROB 535 Perception Project/test/output.csv\", \"w\")\n",
        "  out_file.write(\"guid/image,label\\n\")\n",
        "\n",
        "  for X, img_dir in test_loader:\n",
        "    if(img_num % 100 == 0):\n",
        "      print(img_num)\n",
        "    img_num += 1\n",
        "    with torch.no_grad():\n",
        "      output = model(X.cuda())\n",
        "      predicted = predictions(output.data)\n",
        "      guid = img_dir[0]\n",
        "      label = predicted[0]\n",
        "      out_file.write(\"{0},{1}\\n\".format(guid, label))\n",
        "  out_file.close()\n",
        "\n",
        "\n",
        "#test_data = CustomImageDataset(\"/content/drive/Shareddrives/ROB 535 Perception Project/test/test.csv\", \"/content/drive/Shareddrives/ROB 535 Perception Project/new_test\", train=False)\n",
        "#test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False, pin_memory=True)\n",
        "\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "stats = []\n",
        "\n",
        "checkpoint = torch.load(\"/content/drive/Shareddrives/ROB 535 Perception Project/final_checkpoints/checkpoint_new_25.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "evaluate_epoch(train_dataloader, val_dataloader, model, criterion, epoch+1, stats)\n",
        "print(stats[-1])\n",
        "#eval_test(test_dataloader, model)\n",
        "\n"
      ],
      "metadata": {
        "id": "b82oBS0P9TvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import glob\n",
        "\n",
        "#This script generates a label file for the test dataset, used by\n",
        "#the CustomDataset class defined below. No need to run this cell, since\n",
        "#the label file already exists\n",
        "\n",
        "test_dir = \"/content/drive/Shareddrives/ROB 535 Perception Project/test\"\n",
        "test_csv = open(\"/content/drive/Shareddrives/ROB 535 Perception Project/test/test.csv\", \"w\")\n",
        "test_csv.write(\"guid/image\\n\")\n",
        "\n",
        "for root, dirs, _ in os.walk(test_dir):\n",
        "    for dir in dirs:\n",
        "        newDir = os.path.join(root, dir)\n",
        "        img_files = newDir + \"/*_image.jpg\"\n",
        "        names = glob.glob(img_files)\n",
        "        names.sort()\n",
        "        for name in names:\n",
        "            name_arr = name.split(\"/\")\n",
        "            guid = name_arr[6]\n",
        "            filename = name_arr[7]\n",
        "            file_arr = filename.split(\"_\")\n",
        "            filenum = file_arr[0]\n",
        "            test_csv.write(\"{0}/{1}\\n\".format(guid,filenum))\n",
        "test_csv.close()\n"
      ],
      "metadata": {
        "id": "DfN0rzDQhwXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import ToPILImage\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "'''\n",
        "This script preprocesses the training images by resizing them to 224x224\n",
        "and saving them to a separate directory. If you are accessing this code through\n",
        "the Shared Drive, there is no need to repeat this process.\n",
        "'''\n",
        "\n",
        "train_dir = \"/content/drive/Shareddrives/ROB 535 Perception Project/trainval\"\n",
        "train_224_dir = \"/content/drive/Shareddrives/ROB 535 Perception Project/new_trainval\"\n",
        "if(not os.path.isdir(train_224_dir)):\n",
        "  os.mkdir(train_224_dir)\n",
        "\n",
        "\n",
        "img_num = 1\n",
        "\n",
        "for root, dirs, _ in os.walk(train_dir):\n",
        "    for dir in dirs:\n",
        "        print(dir)\n",
        "        old_dir = os.path.join(root, dir)\n",
        "        new_dir = os.path.join(train_224_dir, dir)\n",
        "        if(not os.path.isdir(new_dir)): \n",
        "          os.mkdir(new_dir)\n",
        "        img_files = old_dir + \"/*_image.jpg\"\n",
        "        names = glob.glob(img_files)\n",
        "        names.sort()\n",
        "        for name in names:\n",
        "          name_arr = name.split(\"/\")\n",
        "          filename = name_arr[7]\n",
        "          image = read_image(name).float()\n",
        "          image = resize(image, (image.shape[0], 224, 224))\n",
        "          image = image.transpose((1,2,0))\n",
        "          out_dir = os.path.join(new_dir, filename)\n",
        "          cv2.imwrite(out_dir, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "          if(img_num % 1000 == 0):\n",
        "            print(img_num)\n",
        "          img_num += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M76qJfASkYs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import ToPILImage\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "'''\n",
        "This script preprocesses the test images by resizing them to 224x224\n",
        "and saving them to a separate directory. If you are accessing this code through\n",
        "the Shared Drive, there is no need to repeat this process.\n",
        "'''\n",
        "\n",
        "\n",
        "test_dir = \"/content/drive/Shareddrives/ROB 535 Perception Project/test\"\n",
        "test_224_dir = \"/content/drive/Shareddrives/ROB 535 Perception Project/new_test\"\n",
        "if(not os.path.isdir(test_224_dir)):\n",
        "  os.mkdir(test_224_dir)\n",
        "\n",
        "\n",
        "img_num = 1\n",
        "\n",
        "for root, dirs, _ in os.walk(test_dir):\n",
        "    for dir in dirs:\n",
        "        old_dir = os.path.join(root, dir)\n",
        "        new_dir = os.path.join(test_224_dir, dir)\n",
        "        if(not os.path.isdir(new_dir)): \n",
        "          os.mkdir(new_dir)\n",
        "        img_files = old_dir + \"/*_image.jpg\"\n",
        "        names = glob.glob(img_files)\n",
        "        names.sort()\n",
        "        for name in names:\n",
        "          name_arr = name.split(\"/\")\n",
        "          filename = name_arr[7]\n",
        "          image = read_image(name).float()\n",
        "          image = resize(image, (image.shape[0], 224, 224))\n",
        "          image = image.transpose((1,2,0))\n",
        "          out_dir = os.path.join(new_dir, filename)\n",
        "          cv2.imwrite(out_dir, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "          if(img_num % 1000 == 0):\n",
        "            print(img_num)\n",
        "          img_num += 1"
      ],
      "metadata": {
        "id": "AwZ5zGmQrBFP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ROB535_FinalProject.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}